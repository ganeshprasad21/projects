{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imp language interpreter using python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this project ,heavily, is based on a jayconrod website\n",
    "\n",
    "9-9-2020\n",
    "ganesh prasad r"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#about imp\n",
    "\n",
    "\n",
    "Assignment statements (all variables are global and can only store integers):\n",
    "\n",
    "x := 1\n",
    "An interpreter for a programming language is a function that, when applied to an expression of the language, performs the actions required to evaluate that expression.\n",
    "Conditional statements:\n",
    "\n",
    "if x = 1 then \n",
    "  y := 2 \n",
    "else \n",
    "  y := 3\n",
    "end\n",
    "\n",
    "While loops:\n",
    "\n",
    "while x < 10 do \n",
    "  x := x + 1\n",
    "end\n",
    "\n",
    "Compound statements (separated by semicolons):\n",
    "\n",
    "x := 1; \n",
    "y := 2\n",
    "\n",
    "\n",
    "example of a program which computes a factorial:\n",
    "\n",
    "n := 5;\n",
    "p := 1;\n",
    "while n > 0 do\n",
    "  p := p * n;\n",
    "  n := n - 1\n",
    "end\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "An interpreter for a programming language is a function that, when applied to an expression of the language, performs the actions required to evaluate that expression.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " *)   intermediate representation is how a program is represented in memory,it is core of interpreters\n",
    " and imp is simple, so, intermediate rep is same as the syntax of code -> we implement a class for each expressions in this representation\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3 steps in interpreter\n",
    "\n",
    "\n",
    "\n",
    "1)split charcters in code into tokens.\n",
    "     |\n",
    "     |\n",
    "     |\n",
    " lexer(tokenize code into easily recognizable code)\n",
    " thus we get tokens\n",
    " \n",
    " 2)organize the tokens we have into AST ->abstract syntax trees.\n",
    "     |->parser using combinator is done in this step to ensure we have ast\n",
    "     this is where we get our intermediate representation\n",
    " \n",
    " 3)EVAL -> PRINT state \n",
    " \n",
    " \n",
    " \n",
    "                 REPL ------= READ(lexer)--->AST----internal representation-----> EVAL------> print loop\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "->the strings are tokenized into easily recognizable parts by lexer by a process known as lexing\n",
    "tokens contain number identifier keyword ,operator\n",
    ">lexer ignores whitespace etc\n",
    ">the tokens are thus sent to next step[\n",
    ">all the tokens are joined into abstract syntax trees which can be evaluated this is known as parsing and parser does this\n",
    ">it is later evaluated\n",
    "\n",
    "\n",
    "now we implement the lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexer(code,token_expressions): #token expressions are defined later they are tuples with token and their type\n",
    "    tokens = [] #tokens that are touples which contains (tkn_txt,type_of_tkn_txt)\n",
    "    pos = 0 #from where the code is chec ked for regex using match (scans for regex in 1st line only)\n",
    "    while (pos<len(code)):\n",
    "        match = None #matched pattern from token_expression in code\n",
    "        for token_expression in token_expressions: #HERE IT IS IMPORTANT TO ORDER THE TOKEN TYPES,RESTRICTED OR RESERVED ARE TO BE GIVEN FIRST SO THAT IDENTIFIERS ARE NOT CONFUSED WITH THEM\n",
    "            tkn_txt_pattern , type_of_tkn_txt = token_expression\n",
    "            regex = re.compile(tkn_txt_pattern) #re.pattern tpe object that can be used to compare from 1st line from pos\n",
    "            match = regex.match(code,pos) #match object that gets the pattern if available from pos only in 1st line from pos\n",
    "            if match:#IF MATCHED\n",
    "                tkn_txt = match.group(0) #gives complete tkn_txt in general it gives groups 1,2,3 etc in regex r'(s).(a|a)' has 2 groups ie()() and 0\n",
    "                #print(\"\"\"X\"\"\",tkn_txt,\"\"\"X\"\"\",type_of_tkn_txt) test\n",
    "                if type_of_tkn_txt: #so that white spaces are ignored in tokens list as it has token_txt_type as none\n",
    "                    tokens.append((tkn_txt,type_of_tkn_txt))\n",
    "                break #FOR LOOP\n",
    "        if not match:\n",
    "            sys.stderr.write(\"bro /sis plz go easy its a beginner project illegal type of code given\")\n",
    "            sys.exit(1)\n",
    "        else: #if matched\n",
    "            pos = match.end() # it gives the position where the matched text tkn_txt ended\n",
    "    return tokens #list of tuples is returned that are the tokens which are given to ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nn', 'ID'),\n",
       " (':=', 'RESERVED'),\n",
       " ('6', 'INT'),\n",
       " (';', 'RESERVED'),\n",
       " ('pp', 'ID'),\n",
       " (':=', 'RESERVED'),\n",
       " ('1', 'INT'),\n",
       " (';', 'RESERVED'),\n",
       " ('while', 'RESERVED'),\n",
       " ('nn', 'ID'),\n",
       " ('>', 'RESERVED'),\n",
       " ('0', 'INT'),\n",
       " ('do', 'RESERVED'),\n",
       " ('pp', 'ID'),\n",
       " (':=', 'RESERVED'),\n",
       " ('pp', 'ID'),\n",
       " ('*', 'RESERVED'),\n",
       " ('nn', 'ID'),\n",
       " (';', 'RESERVED'),\n",
       " ('nn', 'ID'),\n",
       " (':=', 'RESERVED'),\n",
       " ('nn', 'ID'),\n",
       " ('-', 'RESERVED'),\n",
       " ('1', 'INT'),\n",
       " ('end', 'RESERVED')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESERVED = 'RESERVED'\n",
    "INT      = 'INT'\n",
    "ID       = 'ID'\n",
    "token_expressions = [\n",
    "    (r'[ \\n\\t]+',              None),#WHITESPACE AND TABS ONE OR MORE ARE TAKEN AS NONE IN MATCH\n",
    "    (r'#[^\\n]*',               None),\n",
    "    (r'\\:=',                   RESERVED),\n",
    "    (r'\\(',                    RESERVED),\n",
    "    (r'\\)',                    RESERVED),\n",
    "    (r';',                     RESERVED),\n",
    "    (r'\\+',                    RESERVED),\n",
    "    (r'-',                     RESERVED),\n",
    "    (r'\\*',                    RESERVED),\n",
    "    (r'/',                     RESERVED),\n",
    "    (r'<=',                    RESERVED),\n",
    "    (r'<',                     RESERVED),\n",
    "    (r'>=',                    RESERVED),\n",
    "    (r'>',                     RESERVED),\n",
    "    (r'=',                     RESERVED),\n",
    "    (r'!=',                    RESERVED),\n",
    "    (r'and',                   RESERVED),\n",
    "    (r'or',                    RESERVED),\n",
    "    (r'not',                   RESERVED),\n",
    "    (r'if',                    RESERVED),\n",
    "    (r'then',                  RESERVED),\n",
    "    (r'else',                  RESERVED),\n",
    "    (r'while',                 RESERVED),\n",
    "    (r'do',                    RESERVED),\n",
    "    (r'end',                   RESERVED),\n",
    "    (r'[0-9]+',                INT),\n",
    "    (r'[A-Za-z][A-Za-z0-9_]*', ID),\n",
    "]\n",
    "code = \"\"\"nn:=6;\n",
    "pp := 1;\n",
    "while nn > 0 do\n",
    "  pp := pp * nn;\n",
    "  nn := nn - 1\n",
    "end\"\"\"\n",
    "lexer(code,token_expressions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #parser combinator"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "parser combinators ultimately take the tokens and return the ast\n",
    "there are many ways to implement parser here we impliment it using combinator\n",
    "so\n",
    "parser combinator(higher order function) -> parcer function(it converts tokens to ast)\n",
    "1)parser takes tokens in stream and creates a part of ast and returns it along with other tokens\n",
    "2)combinator takes in parsers and create parsers for the whole language"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "here we define a result class first which is the return type of a parser\n",
    "and then define a generic parser class later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here resul class is defined\n",
    "class Result:\n",
    "    def __init__(self,value,position):\n",
    "        self.value = value\n",
    "        self.position = position\n",
    "    def __repr__(self):\n",
    "        return f'[{self.value},{self.position}]'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
